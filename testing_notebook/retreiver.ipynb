{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "841e7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:__main__:Initializing vector store...\n",
      "INFO:__main__:Deleted existing collection\n",
      "ERROR:__main__:Error loading Excel file: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.\n",
      "ERROR:__main__:Failed to initialize vector store\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class SentenceTransformerEmbeddings:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts).tolist()\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode(text).tolist()\n",
    "\n",
    "# Initialize models\n",
    "bi_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "DATA_FILE = './data_oncology.xlsx'\n",
    "VECTOR_STORE_DIR = './chroma_db_oncology'\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def _remove_duplicates(df: pd.DataFrame, similarity_threshold: float = 0.85) -> pd.DataFrame:\n",
    "    logger.info(\"Removing duplicates from dataset\")\n",
    "    print(f\"Initial number of entries: {len(df)}\")\n",
    "    \n",
    "    # 1. Remove exact duplicates\n",
    "    df = df.drop_duplicates(subset=['Question', 'Answer'], keep='first')\n",
    "    print(f\"After removing exact duplicates: {len(df)}\")\n",
    "    \n",
    "    # 2. Remove similar questions\n",
    "    if len(df) > 1:\n",
    "        questions = df['Question'].tolist()\n",
    "        question_embeddings = bi_encoder.encode(questions)\n",
    "        similarity_matrix = np.dot(question_embeddings, question_embeddings.T)\n",
    "        \n",
    "        to_drop = set()\n",
    "        for i in range(len(df)):\n",
    "            if i in to_drop:\n",
    "                continue\n",
    "            for j in range(i + 1, len(df)):\n",
    "                if j in to_drop:\n",
    "                    continue\n",
    "                if similarity_matrix[i, j] > similarity_threshold:\n",
    "                    if len(df.iloc[i]['Answer']) < len(df.iloc[j]['Answer']):\n",
    "                        to_drop.add(i)\n",
    "                    else:\n",
    "                        to_drop.add(j)\n",
    "        \n",
    "        df = df.drop(df.index[list(to_drop)])\n",
    "        print(f\"After removing similar questions: {len(df)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_vectorstore():\n",
    "    embeddings = SentenceTransformerEmbeddings(bi_encoder)\n",
    "    \n",
    "    try:\n",
    "        import chromadb\n",
    "        client = chromadb.PersistentClient(path=str(VECTOR_STORE_DIR))\n",
    "        client.delete_collection(\"oncology_qa\")\n",
    "        logger.info(\"Deleted existing collection\")\n",
    "    except Exception as e:\n",
    "        logger.info(f\"No existing collection to delete: {e}\")\n",
    "    \n",
    "    vector_store = Chroma(\n",
    "        collection_name=\"oncology_qa\",\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=str(VECTOR_STORE_DIR)\n",
    "    )\n",
    "    \n",
    "    try:            \n",
    "        oncology_data = pd.read_excel(DATA_FILE)\n",
    "        logger.info(f\"Loaded {len(oncology_data)} rows from Excel\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading Excel file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    oncology_data = _remove_duplicates(oncology_data)\n",
    "    \n",
    "    documents = []\n",
    "    for _, row in oncology_data.iterrows():\n",
    "        content = f\"Question: {row['Question']}\\nAnswer: {row['Answer']}\"\n",
    "        metadata = {\"Question\": row['Question'], \"Answer\": row['Answer']}\n",
    "        documents.append(Document(page_content=content, metadata=metadata))\n",
    "    \n",
    "    vector_store.add_documents(documents=documents)\n",
    "    logger.info(f\"Vector store created with {len(documents)} documents.\")\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "def main():\n",
    "    logger.info(\"Initializing vector store...\")\n",
    "    vector_store = create_vectorstore()\n",
    "    if vector_store:\n",
    "        logger.info(\"Vector store initialized successfully\")\n",
    "        return vector_store\n",
    "    else:\n",
    "        logger.error(\"Failed to initialize vector store\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee16c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from sentence_transformers import CrossEncoder\n",
    "from typing import List, Dict, Any\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize cross-encoder for re-ranking\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "def format_result(doc: Document, score: float = 1.0) -> Dict[str, Any]:\n",
    "    \"\"\"Format a document into a result dictionary.\"\"\"\n",
    "    return {\n",
    "        \"question\": doc.metadata.get('Question', ''),\n",
    "        \"answer\": doc.metadata.get('Answer', ''),\n",
    "        \"score\": float(score)\n",
    "    }\n",
    "\n",
    "def get_vector_store() -> Chroma:\n",
    "    \"\"\"Initialize and return the Chroma vector store.\"\"\"\n",
    "    embeddings = SentenceTransformerEmbeddings(bi_encoder)\n",
    "    return Chroma(\n",
    "        collection_name=\"oncology_qa\",\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=str(VECTOR_STORE_DIR)\n",
    "    )\n",
    "\n",
    "def search_qa(query: str, k: int = 5, use_cross_encoder: bool = False) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Search the QA knowledge base for relevant answers.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        k: Number of results to return\n",
    "        use_cross_encoder: Whether to use cross-encoder for re-ranking\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing question, answer, and score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Searching knowledge base for: {query}\")\n",
    "        \n",
    "        vector_store = get_vector_store()\n",
    "        fetch_count = k * 3 if use_cross_encoder else k\n",
    "        initial_results = vector_store.similarity_search(query, k=fetch_count)\n",
    "        \n",
    "        if not initial_results:\n",
    "            return []\n",
    "            \n",
    "        if not use_cross_encoder:\n",
    "            return [format_result(doc, ) for doc in initial_results[:k]]\n",
    "        \n",
    "        \n",
    "        # Re-rank with cross-encoder\n",
    "        query_doc_pairs = [(query, doc.page_content) for doc in initial_results]\n",
    "        scores = cross_encoder.predict(query_doc_pairs)\n",
    "        \n",
    "        # Combine results with scores and sort\n",
    "        scored_results = zip(initial_results, scores)\n",
    "        top_results = sorted(scored_results, key=lambda x: x[1], reverse=True)[:k]\n",
    "        \n",
    "        return [format_result(doc, score) for doc, score in top_results]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Search failed for query '{query}': {str(e)}\", exc_info=True)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e43d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Searching knowledge base for: How is breast cancer treated?\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.53it/s]\n"
     ]
    }
   ],
   "source": [
    "query = \"How is breast cancer treated?\"\n",
    "\n",
    "results = search_qa(query, k=5, use_cross_encoder=True)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Question: {result['question']}\\nAnswer: {result['answer']}\\nScore: {result['score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdc530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
